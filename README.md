
## Video-XL Family: Efficient VLMs for Extremely Long Video Understanding


## News
- [2025/06/03] ðŸ”¥ [Video-XL2](Video-XL-2) is released, which achieves state-of-the-art results on several long video understanding benchmarks.
- [2025/04/19] ðŸŽ‰ Most of the Video-XL-Pro [training data](https://huggingface.co/datasets/lxr2003/Video-XL-Pro-Training/tree/main) is released.
- [2025/04/07] ðŸŽ‰ Video-XL has been selected as Oral presentation for CVPR.  
- [2025/03/16] ðŸŽ‰ [Video-XL-Pro](Video-XL-Pro) is released, which can process 10000 frames on an 80G GPU and achieves promising results with only 3B parameters.
- [2025/02/27] ðŸŽ‰ Video-XL has been accepted by CVPR 2025!
- [2024/12/22] ðŸ”¥ Most of the [training data](https://huggingface.co/datasets/sy1998/Video_XL_Training/tree/main) is released. 
- [2024/10/17] ðŸ”¥ Video-XL-7B weight is released, which can process max 1024 frames. 
- [2024/10/15] ðŸ”¥ [Video-XL](Video-XL) is released,  including model, training and evaluation code.



## Citation
If you find this repository useful, please consider giving a star :star: and citation

```
@article{shu2024video,
  title={Video-XL: Extra-Long Vision Language Model for Hour-Scale Video Understanding},
  author={Shu, Yan and Zhang, Peitian and Liu, Zheng and Qin, Minghao and Zhou, Junjie and Huang, Tiejun and Zhao, Bo},
  journal={arXiv preprint arXiv:2409.14485},
  year={2024}
}

@article{liu2025video,
  title={Video-XL-Pro: Reconstructive Token Compression for Extremely Long Video Understanding},
  author={Liu, Xiangrui and Shu, Yan and Liu, Zheng and Li, Ao and Tian, Yang and Zhao, Bo},
  journal={arXiv preprint arXiv:2503.18478},
  year={2025}
}

@article{qin2025video,
  title={Video-XL-2: Towards Very Long-Video Understanding Through Task-Aware KV Sparsification},
  author={Qin, Minghao and Liu, Xiangrui and Liang, Zhengyang and Shu, Yan and Yuan, Huaying and Zhou, Juenjie and Xiao, Shitao and Zhao, Bo and Liu, Zheng},
  journal={arXiv preprint arXiv:2506.19225},
  year={2025}
} 
```

## Acknowledgement
- LongVA: the codebase we built upon. 
- LMMs-Eval: the codebase we used for evaluation.
- Activation Beacon: The compression methods we referring.

## License
This project utilizes certain datasets and checkpoints that are subject to their respective original licenses. Users must comply with all terms and conditions of these original licenses.
The content of this project itself is licensed under the [Apache license 2.0](./LICENSE).




